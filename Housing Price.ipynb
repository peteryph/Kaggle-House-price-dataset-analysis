{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import pandas\n",
    "import plotly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# sklearn basic\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn model\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "\n",
    "\n",
    "#XGboost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# ensemble learning\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"train.csv\", header = 0)\n",
    "df = df.drop(columns = [\"Street\", \"Utilities\", \"PoolQC\", \"GarageYrBlt\"])\n",
    "# df = df.drop(columns = [\"Street\", \"Utilities\", \"PoolQC\", \"GarageYrBlt\", \"MoSold\", \"YrSold\", \"YearBuilt\", \"YearRemodAdd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to one-hot**\n",
    "- MSSubClass, MSZoning, Street, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, Foundation, Heating, Electrical, Functional, GarageType, PavedDrive, Fence, MiscFeature, SaleType, SaleConditionc, Alley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_list =[\"Alley\",\"MSSubClass\", \"MSZoning\", \"LotConfig\", \"LandSlope\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"Electrical\", \"Functional\", \"GarageType\", \"PavedDrive\", \"Fence\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cate_list:\n",
    "    lis = []\n",
    "    for i in df[c].unique():\n",
    "        if(not isinstance(i, float)):\n",
    "#             if(not math.isnan(i)):\n",
    "            lis.append((i))\n",
    "        \n",
    "    Type = pandas.DataFrame(columns = sorted(lis, reverse = False)) # create the new dataframe base the all the type key found\n",
    "    key = list(Type.keys()) # loop over all the types\n",
    "    count = 0\n",
    "\n",
    "    for i in df[c].tolist():\n",
    "        value_list = np.zeros(len(key)).reshape(1,len(key)) # default all 0\n",
    "        value_list = pandas.DataFrame(value_list, columns = key)\n",
    "        Type = Type.append(value_list) # append the new row into dataframe\n",
    "        Type.iloc[count][(i)] = 1 # the select type feature will be 1\n",
    "        count += 1 # index the current row\n",
    "        \n",
    "    for i in Type.keys():\n",
    "        df[str(c)+str(i)] = Type[i].tolist()\n",
    "df = df.drop(columns = cate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to Boolean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CA_list = df[\"CentralAir\"].tolist()\n",
    "CA_Convert_list = []\n",
    "for i in CA_list:\n",
    "    if(i == \"N\"):\n",
    "        CA_Convert_list.append(0)\n",
    "    else:\n",
    "        CA_Convert_list.append(1)\n",
    "df[\"CentralAir_New\"] = CA_Convert_list\n",
    "df = df.drop(columns = [\"CentralAir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to Rank**\n",
    "\n",
    "- LotShape, LandContour, ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, HeatingQC, KitchenQual, FireplaceQu, GarageFinish, GarageQual, GarageCond, PoolQC\n",
    "\n",
    "- OverallQual, OverallCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LotShape_Convert_list = []\n",
    "for i in df[\"LotShape\"].tolist():\n",
    "    if(i == \"Reg\"):\n",
    "        LotShape_Convert_list.append(3)\n",
    "    elif(i == \"IR1\"):\n",
    "        LotShape_Convert_list.append(2)\n",
    "    elif(i == \"IR2\"):\n",
    "        LotShape_Convert_list.append(1)\n",
    "    elif(i == \"IR3\"):\n",
    "        LotShape_Convert_list.append(0)\n",
    "df[\"LotShape_New\"] = LotShape_Convert_list\n",
    "df = df.drop(columns = [\"LotShape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LandContour_Convert_list = []\n",
    "for i in df[\"LandContour\"].tolist():\n",
    "    if(i == \"Lvl\"):\n",
    "        LandContour_Convert_list.append(3)\n",
    "    elif(i == \"Bnk\"):\n",
    "        LandContour_Convert_list.append(2)\n",
    "    elif(i == \"HLS\"):\n",
    "        LandContour_Convert_list.append(1)\n",
    "    elif(i == \"Low\"):\n",
    "        LandContour_Convert_list.append(0)\n",
    "df[\"LandContour_New\"] = LandContour_Convert_list\n",
    "df = df.drop(columns = [\"LandContour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in [\"ExterCond\", \"ExterQual\", \"HeatingQC\", \"KitchenQual\"]:\n",
    "    ExterQual_Convert_list = []\n",
    "    for i in df[k].tolist():\n",
    "        if(i == \"Ex\"):\n",
    "            ExterQual_Convert_list.append(4)\n",
    "        elif(i == \"Gd\"):\n",
    "            ExterQual_Convert_list.append(3)\n",
    "        elif(i == \"TA\"):\n",
    "            ExterQual_Convert_list.append(2)\n",
    "        elif(i == \"Fa\"):\n",
    "            ExterQual_Convert_list.append(1)\n",
    "        elif(i == \"Po\"):\n",
    "            ExterQual_Convert_list.append(0)\n",
    "    df[str(k)+\"_New\"] = ExterQual_Convert_list\n",
    "    df = df.drop(columns = [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"BsmtExposure\"]:\n",
    "    ExterQual_Convert_list = []\n",
    "    for i in df[k].tolist():\n",
    "        if(not isinstance(i, float)):\n",
    "            if(i == \"Gd\"):\n",
    "                ExterQual_Convert_list.append(4)\n",
    "            elif(i == \"Av\"):\n",
    "                ExterQual_Convert_list.append(3)\n",
    "            elif(i == \"Mn\"):\n",
    "                ExterQual_Convert_list.append(2)\n",
    "            elif(i == \"No\"):\n",
    "                ExterQual_Convert_list.append(1)\n",
    "        else:\n",
    "            ExterQual_Convert_list.append(0)\n",
    "\n",
    "\n",
    "    df[str(k)+\"_New\"] = ExterQual_Convert_list\n",
    "    df = df.drop(columns = [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"BsmtCond\", \"BsmtQual\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\"]:\n",
    "    BsmtQual_Convert_list = []\n",
    "    for i in df[k].tolist():\n",
    "        if(not isinstance(i, float)):\n",
    "            if(i == \"Ex\"):\n",
    "                BsmtQual_Convert_list.append(5)\n",
    "            elif(i == \"Gd\"):\n",
    "                BsmtQual_Convert_list.append(4)\n",
    "            elif(i == \"TA\"):\n",
    "                BsmtQual_Convert_list.append(3)\n",
    "            elif(i == \"Fa\"):\n",
    "                BsmtQual_Convert_list.append(2)\n",
    "            elif(i == \"Po\"):\n",
    "                BsmtQual_Convert_list.append(1)\n",
    "            elif(i == \"NA\"):\n",
    "                BsmtQual_Convert_list.append(0)\n",
    "        else:\n",
    "            BsmtQual_Convert_list.append(0)\n",
    "\n",
    "\n",
    "    df[str(k)+\"_New\"] = BsmtQual_Convert_list\n",
    "    df = df.drop(columns = [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in [\"BsmtFinType1\", \"BsmtFinType2\"]:\n",
    "    BsmtQual_Convert_list = []\n",
    "    for i in df[k].tolist():\n",
    "        if(not isinstance(i, float)):\n",
    "            if(i == \"GLQ\"):\n",
    "                BsmtQual_Convert_list.append(6)\n",
    "            elif(i == \"ALQ\"):\n",
    "                BsmtQual_Convert_list.append(5)\n",
    "            elif(i == \"Rec\"):\n",
    "                BsmtQual_Convert_list.append(4)\n",
    "            elif(i == \"BLQ\"):\n",
    "                BsmtQual_Convert_list.append(3)\n",
    "            elif(i == \"LwQ\"):\n",
    "                BsmtQual_Convert_list.append(2)\n",
    "            elif(i == \"Unf\"):\n",
    "                BsmtQual_Convert_list.append(1)\n",
    "            elif(i == \"NA\"):\n",
    "                BsmtQual_Convert_list.append(0)\n",
    "        else:\n",
    "            BsmtQual_Convert_list.append(0)\n",
    "\n",
    "\n",
    "    df[str(k)+\"_New\"] = BsmtQual_Convert_list\n",
    "    df = df.drop(columns = [k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"GarageFinish\"]:\n",
    "    BsmtQual_Convert_list = []\n",
    "    for i in df[k].tolist():\n",
    "        if(not isinstance(i, float)):\n",
    "            if(i == \"Fin\"):\n",
    "                BsmtQual_Convert_list.append(3)\n",
    "            elif(i == \"RFn\"):\n",
    "                BsmtQual_Convert_list.append(2)\n",
    "            elif(i == \"Unf\"):\n",
    "                BsmtQual_Convert_list.append(1)\n",
    "            elif(i == \"NA\"):\n",
    "                BsmtQual_Convert_list.append(0)\n",
    "        else:\n",
    "            BsmtQual_Convert_list.append(0)\n",
    "df[str(k)+\"_New\"] = BsmtQual_Convert_list\n",
    "df = df.drop(columns = [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan to 0\n",
    "df[\"LotFrontage\"] = df[\"LotFrontage\"].fillna(0).tolist()\n",
    "df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0).tolist()\n",
    "df = df.drop(columns = [\"Id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale_df = df.drop(columns = [\"SalePrice\"])\n",
    "keys = list(scale_df.keys())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "scaler.fit(scale_df)\n",
    "scale_df = scaler.transform(scale_df)\n",
    "scale_df = pandas.DataFrame(scale_df, columns = keys)\n",
    "scale_df[\"SalePrice\"] = df[\"SalePrice\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = scale_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidate_components = range(10, 240, 30)\n",
    "explained_ratios = []\n",
    "for c in candidate_components:\n",
    "    pca = PCA(n_components=c)\n",
    "    X_pca = pca.fit_transform(df.drop(columns = [\"SalePrice\"]))\n",
    "    explained_ratios.append(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=144)\n",
    "plt.grid()\n",
    "plt.plot(candidate_components, explained_ratios)\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained variance ratio for PCA')\n",
    "plt.yticks(np.arange(0.5, 1.05, .05))\n",
    "plt.xticks(np.arange(0, 300, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"SalePrice\"].tolist()\n",
    "X = df.drop(columns = [\"SalePrice\"]).values.tolist()\n",
    "pca = sklearn.decomposition.PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(\n",
    "    df.drop(columns = \"SalePrice\").values.tolist(), \n",
    "    df[\"SalePrice\"].tolist(),\n",
    "    test_size=0.07, \n",
    "    random_state=42)\n",
    "\n",
    "# stacking dataset or vaild for boosting\n",
    "Train_Stacking_X = Train_X[:150]\n",
    "Train_Stacking_Y = Train_Y[:150]\n",
    "\n",
    "Train_X = Train_X[150:]\n",
    "Train_Y = Train_Y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas shuffle\n",
    "dataset = shuffle(df)\n",
    "Test = dataset[:100]\n",
    "Train = dataset[100:]\n",
    "\n",
    "Train_Stacking = Train[:300]\n",
    "Train = Train[300:]\n",
    "\n",
    "Test_X = Test.drop(columns = \"SalePrice\").values.tolist()\n",
    "Test_Y = Test[\"SalePrice\"].tolist()\n",
    "\n",
    "Train_X = Train.drop(columns = \"SalePrice\").values.tolist()\n",
    "Train_Y = Train[\"SalePrice\"].tolist()\n",
    "\n",
    "Train_Stacking_X = Train_Stacking.drop(columns = \"SalePrice\").values.tolist()\n",
    "Train_Stacking_Y = Train_Stacking[\"SalePrice\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After PCA\n",
    "Test = X[:100]\n",
    "Train = X[100:]\n",
    "\n",
    "Test_X = Test\n",
    "Test_Y = Y[:100]\n",
    "\n",
    "Train_X = Train\n",
    "Train_Y = Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam boost for the model and return the best selection via given datasets\n",
    "def Ada_Model(model, Train_X, Train_Y, Vail_X, Vail_Y):\n",
    "    highest = 0\n",
    "    coeff = 0\n",
    "    rng = np.random.RandomState(1)\n",
    "    for i in range(1, 20):\n",
    "        AdaBoost_model = AdaBoostRegressor(base_estimator=model, n_estimators=i, random_state=rng)\n",
    "        AdaBoost_model.fit(Train_X, Train_Y)\n",
    "        curr_score = AdaBoost_model.score(Vail_X, Vail_Y)\n",
    "        if(highest < curr_score):\n",
    "            highest = curr_score\n",
    "            coeff = i\n",
    "    return coeff, highest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging(model, Train_X, Train_Y, Vail_X, Vail_Y):  \n",
    "    highest = 0\n",
    "    coeff = 0\n",
    "    rng = np.random.RandomState(1)\n",
    "    for i in range(1, 20):\n",
    "        Bagging_Model = BaggingRegressor(base_estimator= model, n_estimators = i, bootstrap=True, warm_start=False) #\n",
    "        Bagging_Model.fit(Train_X, Train_Y)\n",
    "        curr_score = Bagging_Model.score(Vail_X, Vail_Y)\n",
    "        if(highest < curr_score):\n",
    "            highest = curr_score\n",
    "            coeff = i\n",
    "    return coeff, highest\n",
    "\n",
    "# sklearn.ensemble.BaggingRegressor(base_estimator=None, \n",
    "# n_estimators=10, \n",
    "# max_samples=1.0, \n",
    "# max_features=1.0, \n",
    "# bootstrap=True, \n",
    "# bootstrap_features=False, \n",
    "# oob_score=False, \n",
    "# warm_start=False, \n",
    "# n_jobs=None, \n",
    "# random_state=None, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBDT(model, Train_X, Train_Y, Vail_X, Vail_Y):\n",
    "    coeff = 0\n",
    "    highest = 0\n",
    "    _range = np.arange(0.01, 1, 0.05)\n",
    "    for i in (_range):\n",
    "        GBDT = GradientBoostingRegressor(init = model, learning_rate = i)\n",
    "        GBDT.fit(Train_X, Train_Y)\n",
    "        curr_score = GBDT.score(Train_Stacking_X, Train_Stacking_Y)\n",
    "        if(highest < curr_score):\n",
    "            highest = curr_score\n",
    "            coeff = i\n",
    "    return coeff, highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(30, 20, 5), learning_rate='constant',\n",
       "             learning_rate_init=0.1, max_iter=1000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = MLPRegressor(solver='adam',  # weight optimization\n",
    "                    activation='relu',  # activation function\n",
    "                    alpha=1e-2, # Regularizer value\n",
    "                    learning_rate_init = 0.1,\n",
    "                    hidden_layer_sizes=(30,20,5), # layer and node (node,node) --> numbers of layers\n",
    "\n",
    "                  random_state=1, #random state\n",
    "                    max_iter = 1000, # max iteration\n",
    "                    early_stopping = True) # early stop\n",
    "\n",
    "NN.fit(Train_X, Train_Y) # fit the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765227063911397"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621464009981835"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.9046479031201354)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(NN, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048061031018695"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_NN = BaggingRegressor(base_estimator= NN, n_estimators = coeff, bootstrap=True, warm_start=False) #\n",
    "Bagging_NN.fit(Train_X, Train_Y)\n",
    "Bagging_NN.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805444810240521"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_NN.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 0.9027425306378715)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosting Net\n",
    "coeff, highest = Ada_Model(Bagging_NN, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764107005334632"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,3):\n",
    "AdaBoost_NN = AdaBoostRegressor(base_estimator=Bagging_NN, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_NN.fit(Train_X, Train_Y)\n",
    "AdaBoost_NN.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576248515610712"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_NN.score(Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.51, 0.9344089223649689)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_NN, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934266867223877"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_NN = GradientBoostingRegressor(init = Bagging_NN, learning_rate = coeff)\n",
    "GBDT_NN.fit(Train_X, Train_Y)\n",
    "GBDT_NN.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171422441659779"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_NN.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"NN\", \n",
    "                    NN.score(Test_X, Test_Y), \n",
    "                    Bagging_NN.score(Test_X, Test_Y),\n",
    "                    AdaBoost_NN.score(Test_X, Test_Y), \n",
    "                    GBDT_NN.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [NN, Bagging_NN, AdaBoost_NN, GBDT_NN]\n",
    "lis_tag = [\"NN\", \"Bagging_NN\", \"AdaBoost_NN\", \"GBDT_NN\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/NN Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic Net + Adam Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608132163178565"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net = ElasticNet(random_state=0, warm_start = True)\n",
    "Net.fit(Train_X, Train_Y)  \n",
    "Net.score(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134309769745292"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.score(Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.5625161723910879)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(Net, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615028073521705"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_Net = BaggingRegressor(base_estimator =  Net, n_estimators = coeff, bootstrap=True, warm_start=False)\n",
    "Bagging_Net.fit(Train_X, Train_Y)\n",
    "Bagging_Net.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.6452908847750574)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosting Net\n",
    "coeff, highest = Ada_Model(Bagging_Net, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664128936487873"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,3):\n",
    "AdaBoost_Net = AdaBoostRegressor(base_estimator=Bagging_Net, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_Net.fit(Train_X, Train_Y)\n",
    "AdaBoost_Net.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6761796347352977"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_Net.score(Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21000000000000002, 0.9426762361825926)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_Net, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825080767462263"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_Net = GradientBoostingRegressor(init = Bagging_Net, learning_rate = coeff)\n",
    "GBDT_Net.fit(Train_X, Train_Y)\n",
    "GBDT_Net.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8948147581521146"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_Net.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"Net\", \n",
    "                    Net.score(Test_X, Test_Y), \n",
    "                    Bagging_Net.score(Test_X, Test_Y), \n",
    "                    AdaBoost_Net.score(Test_X, Test_Y), \n",
    "                    GBDT_Net.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [Net, Bagging_Net, AdaBoost_Net, GBDT_Net]\n",
    "lis_tag = [\"Net\", \"Bagging_Net\", \"AdaBoost_Net\", \"GBDT_Net\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/Net Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = 0\n",
    "coeff = 0\n",
    "for i in np.arange(0, 10, 0.1): # find the best regularizer value\n",
    "    ridge = Ridge(alpha=i)\n",
    "    ridge.fit(Train_X, Train_Y)\n",
    "#     ridge.score(Train_X, Train_Y)\n",
    "    curr_score = ridge.score(Train_Stacking_X, Train_Stacking_Y)\n",
    "    if(highest < curr_score):\n",
    "        highest = curr_score\n",
    "        coeff = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.886179169216485, 0.2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest,coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9191594328003637"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=coeff)\n",
    "ridge.fit(Train_X, Train_Y)\n",
    "ridge.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649592609207901"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 0.8961068897314984)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(ridge, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8593121783407439"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_ridge = BaggingRegressor(base_estimator =  ridge, n_estimators = coeff, bootstrap=True, warm_start=False)\n",
    "Bagging_ridge.fit(Train_X, Train_Y)\n",
    "Bagging_ridge.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.8946954755455747)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosting Net\n",
    "coeff, highest = Ada_Model(Bagging_ridge, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845695757517445"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,3):\n",
    "AdaBoost_ridge = AdaBoostRegressor(base_estimator=Bagging_ridge, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_ridge.fit(Train_X, Train_Y)\n",
    "AdaBoost_ridge.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490501537122466"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_ridge.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31000000000000005, 0.9404512538512528)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_ridge, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898090425116809"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_ridge = GradientBoostingRegressor(init = ridge, learning_rate = coeff)\n",
    "GBDT_ridge.fit(Train_X, Train_Y)\n",
    "GBDT_ridge.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534430532190186"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_ridge.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"Ridge\", \n",
    "                    ridge.score(Test_X, Test_Y), \n",
    "                    Bagging_ridge.score(Test_X, Test_Y), \n",
    "                    AdaBoost_ridge.score(Test_X, Test_Y), \n",
    "                    GBDT_ridge.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [ridge, Bagging_ridge, AdaBoost_ridge, GBDT_ridge]\n",
    "lis_tag = [\"ridge\", \"Bagging_ridge\", \"AdaBoost_ridge\", \"GBDT_ridge\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/Ridge Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9221279413928494"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.43628072406134e+19"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 0\n",
    "highest = 0\n",
    "for i in range(1,10):\n",
    "    Tree = tree.DecisionTreeRegressor(max_depth = i)\n",
    "    Tree.fit(Train_X, Train_Y)\n",
    "    curr_score = Tree.score(Train_Stacking_X, Train_Stacking_Y)\n",
    "    if(highest < curr_score):\n",
    "        highest = curr_score\n",
    "        coeff = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524756492976404, 8)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest, coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644751408987077"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = tree.DecisionTreeRegressor(max_depth = coeff)\n",
    "Tree.fit(Train_X, Train_Y)\n",
    "Tree.score(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328186006279456"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree.score(Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 0.9030511872299127)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(Tree, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596254745612443"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_Tree = BaggingRegressor(base_estimator =  Tree, n_estimators = coeff, bootstrap=True, warm_start=False)\n",
    "Bagging_Tree.fit(Train_X, Train_Y)\n",
    "Bagging_Tree.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8829087829103388"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_Tree.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 0.9120645437251983)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Ada_Model(Bagging_Tree, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822806788032007"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_Tree = AdaBoostRegressor(base_estimator=Bagging_Tree, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_Tree.fit(Train_X, Train_Y)\n",
    "AdaBoost_Tree.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8897070558260104"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_Tree.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.060000000000000005, 0.9300214982302184)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_Tree, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827489758559167"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_Tree = GradientBoostingRegressor(init = Bagging_Tree, learning_rate = coeff)\n",
    "GBDT_Tree.fit(Train_X, Train_Y)\n",
    "GBDT_Tree.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8752864254675917"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_Tree.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"Tree\", \n",
    "                    Tree.score(Test_X, Test_Y), \n",
    "                    Bagging_Tree.score(Test_X, Test_Y), \n",
    "                    AdaBoost_Tree.score(Test_X, Test_Y), \n",
    "                    GBDT_Tree.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [Tree, Bagging_Tree, AdaBoost_Tree, GBDT_Tree]\n",
    "lis_tag = [\"Tree\", \"Bagging_Tree\", \"AdaBoost_Tree\", \"GBDT_Tree\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/Tree Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9062298411606639"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BR = BayesianRidge()\n",
    "BR.fit(Train_X, Train_Y)\n",
    "BR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681998400678294"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.8953551642548773)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(BR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024495582226408"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_BR = BaggingRegressor(base_estimator =  BR, n_estimators = coeff, bootstrap=True, warm_start=False)\n",
    "Bagging_BR.fit(Train_X, Train_Y)\n",
    "Bagging_BR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728112164839084"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_BR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.8958365081322586)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosting Net\n",
    "coeff, highest = Ada_Model(Bagging_BR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821319204180762"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,3):\n",
    "AdaBoost_BR = AdaBoostRegressor(base_estimator=Bagging_BR, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_BR.fit(Train_X, Train_Y)\n",
    "AdaBoost_BR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168658462218485"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_BR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36000000000000004, 0.9418871539264054)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_BR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913931196754711"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_BR = GradientBoostingRegressor(init = ridge, learning_rate = coeff)\n",
    "GBDT_BR.fit(Train_X, Train_Y)\n",
    "GBDT_BR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8838305534346554"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_BR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"BR\", \n",
    "                    BR.score(Test_X, Test_Y), \n",
    "                    Bagging_BR.score(Test_X, Test_Y), \n",
    "                    AdaBoost_BR.score(Test_X, Test_Y), \n",
    "                    GBDT_BR.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [BR, Bagging_BR, AdaBoost_BR, GBDT_BR]\n",
    "lis_tag = [\"BR\", \"Bagging_BR\", \"AdaBoost_BR\", \"GBDT_BR\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/BR Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "highest = 0\n",
    "node = 0\n",
    "for i in range(1,100):\n",
    "    neigh = KNeighborsRegressor(n_neighbors = i, algorithm = \"auto\", weights = \"distance\") #n_neighbors=2\n",
    "    neigh.fit(Train_X, Train_Y) \n",
    "#     curr_score = neigh.score(Train_X[:n], Train_Y[:n])\n",
    "    curr_score = neigh.score(Train_Stacking_X, Train_Stacking_Y)\n",
    "    if(highest < curr_score):\n",
    "        highest = curr_score\n",
    "        node = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.7204476074441567)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032469819887143"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNR = KNeighborsRegressor(n_neighbors = node, algorithm = \"auto\", weights = \"distance\") #n_neighbors=2\n",
    "KNR.fit(Train_X, Train_Y) \n",
    "KNR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032469819887143"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 0.7734546150189388)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(KNR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_KNR = BaggingRegressor(base_estimator =  KNR, n_estimators = coeff, bootstrap=False, warm_start=True)\n",
    "Bagging_KNR.fit(Train_X, Train_Y)\n",
    "Bagging_KNR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032469819887143"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_KNR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 0.7469084608436959)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Ada_Model(Bagging_KNR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920397629912991"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_KNR = AdaBoostRegressor(base_estimator=Bagging_KNR, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_KNR.fit(Train_X, Train_Y)\n",
    "AdaBoost_KNR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999036128246037"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_KNR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01, 0.7204476074441567)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_KNR, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_KNR = GradientBoostingRegressor(init = Bagging_KNR, learning_rate = coeff)\n",
    "GBDT_KNR.fit(Train_X, Train_Y)\n",
    "GBDT_KNR.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032469819887144"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_KNR.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"KNR\", \n",
    "                    KNR.score(Test_X, Test_Y), \n",
    "                    Bagging_KNR.score(Test_X, Test_Y),\n",
    "                    AdaBoost_KNR.score(Test_X, Test_Y), \n",
    "                    GBDT_KNR.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [KNR, Bagging_KNR, AdaBoost_KNR, GBDT_KNR]\n",
    "lis_tag = [\"KNR\", \"Bagging_KNR\", \"AdaBoost_KNR\", \"GBDT_KNR\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/KNR Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604894461079304"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly = SVR(kernel='poly', C=1e7, gamma='auto', degree=3, epsilon=.1, coef0=1)\n",
    "svr_poly.fit(Train_X, Train_Y)\n",
    "svr_poly.score(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004236321539211"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly.score(Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.9058165076610192)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Bagging(svr_poly, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604894461079304"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_svr = BaggingRegressor(base_estimator =  svr_poly, n_estimators = coeff, bootstrap=False, warm_start=True)\n",
    "Bagging_svr.fit(Train_X, Train_Y)\n",
    "Bagging_svr.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004236321539211"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bagging_svr.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.9141149156152574)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = Ada_Model(Bagging_svr, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9114257876149752"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_svr = AdaBoostRegressor(base_estimator=Bagging_svr, n_estimators=coeff, random_state=rng)\n",
    "AdaBoost_svr.fit(Train_X, Train_Y)\n",
    "AdaBoost_svr.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908434877567564"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_svr.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6100000000000001, 0.9398800562416164)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff, highest = GBDT(Bagging_svr, Train_X, Train_Y, Train_Stacking_X, Train_Stacking_Y)\n",
    "coeff, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:351: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999453621250671"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_svr = GradientBoostingRegressor(init = Bagging_svr, learning_rate = coeff)\n",
    "GBDT_svr.fit(Train_X, Train_Y)\n",
    "GBDT_svr.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7899992249554324"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBDT_svr.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_list.append([\"SVR\", \n",
    "                    svr_poly.score(Test_X, Test_Y), \n",
    "                    Bagging_svr.score(Test_X, Test_Y), \n",
    "                    AdaBoost_svr.score(Test_X, Test_Y), \n",
    "                    GBDT_svr.score(Test_X, Test_Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "lis = [svr_poly, Bagging_svr, AdaBoost_svr, GBDT_svr]\n",
    "lis_tag = [\"svr_poly\", \"Bagging_svr\", \"AdaBoost_svr\", \"GBDT_svr\"]\n",
    "for i in range(0,len(lis)):\n",
    "    filename = os.getcwd()+'/SVR Model/'+str(lis_tag[i])+'.sav'\n",
    "    pickle.dump(lis[i], open(filename, 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 5, \n",
    "                          alpha = 10, \n",
    "                          n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective = \"reg:linear\", reg_lambda=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=70,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=2, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9553974408407383"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.score(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480248024991448"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all, strong, and weak models to ensemble\n",
    "\n",
    "all_models = [NN, BR, Net, AdaBoost_Net, Tree, AdaBoost_Tree, ridge, KNR, AdaBoost_KNR, svr_poly]\n",
    "all_models_labels = [\"NN\", \"BR\", \"Net\", \"AdaBoost_Net\", \"Tree\", \"AdaBoost_Tree\", \"Ridge\", \"KNR\", \"AdaBoost_KNR\", \"SVR\"]\n",
    "\n",
    "strong_models = [NN, BR, AdaBoost_Tree, ridge, svr_poly]\n",
    "strong_models_labels = [\"NN\", \"BR\", \"AdaBoost_Tree\", \"Ridge\", \"SVR\"]\n",
    "\n",
    "weak_models = [AdaBoost_Net, Tree, KNR]\n",
    "weak_models_labels = [\"AdaBoost_Net\", \"Tree\", \"KNR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble Learning - Voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lis = []\n",
    "for i in zip(all_models_labels,all_models):\n",
    "    lis.append(i)\n",
    "\n",
    "VR_all_models = VotingRegressor(estimators=lis)\n",
    "VR_all_models.fit(Train_X, Train_Y)\n",
    "VR_all_models.score(Train_X, Train_Y) # Training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VR_all_models.score(Test_X, Test_Y) # Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting with strong models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for i in zip(strong_models_labels,strong_models):\n",
    "    lis.append(i)\n",
    "\n",
    "VR_strong_models = VotingRegressor(estimators=lis)\n",
    "VR_strong_models.fit(Train_X, Train_Y)\n",
    "VR_strong_models.score(Train_X, Train_Y) # Training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VR_strong_models.score(Test_X, Test_Y) # Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting with weak models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for i in zip(weak_models_labels,weak_models):\n",
    "    lis.append(i)\n",
    "\n",
    "VR_weak_models = VotingRegressor(estimators=lis)\n",
    "VR_weak_models.fit(Train_X, Train_Y)\n",
    "VR_weak_models.score(Train_X, Train_Y) # Training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VR_weak_models.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble Learning - Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = MLPRegressor() # early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stregr = StackingRegressor(regressors=all_models, \n",
    "                           meta_regressor=meta)\n",
    "\n",
    "\n",
    "stregr.fit(Train_Stacking_X, Train_Stacking_Y)\n",
    "stregr.score(Train_Stacking_X, Train_Stacking_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stregr.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking with strong models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_strong = StackingRegressor(regressors=strong_models, meta_regressor=meta) # strong models\n",
    "stack_strong.fit(Train_Stacking_X, Train_Stacking_Y)\n",
    "stack_strong.score(Train_Stacking_X, Train_Stacking_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_strong.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking with weak models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stregr_weak = StackingRegressor(regressors=weak_models, meta_regressor=meta) # weak models\n",
    "stregr_weak.fit(Train_Stacking_X, Train_Stacking_Y)\n",
    "stregr_weak.score(Train_Stacking_X, Train_Stacking_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stregr_weak.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging_all_models.score(Test_X, Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Raw Model</th>\n",
       "      <th>Bagging Model</th>\n",
       "      <th>AdaBoost Model</th>\n",
       "      <th>GBDT Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.862146</td>\n",
       "      <td>0.794817</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>0.917142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Net</td>\n",
       "      <td>0.613431</td>\n",
       "      <td>0.608018</td>\n",
       "      <td>0.676180</td>\n",
       "      <td>0.894815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.864959</td>\n",
       "      <td>0.872336</td>\n",
       "      <td>0.849050</td>\n",
       "      <td>0.853443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.882975</td>\n",
       "      <td>0.889707</td>\n",
       "      <td>0.875286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>0.880822</td>\n",
       "      <td>0.816866</td>\n",
       "      <td>0.883831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNR</td>\n",
       "      <td>0.703247</td>\n",
       "      <td>0.703247</td>\n",
       "      <td>0.699904</td>\n",
       "      <td>0.703247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.900424</td>\n",
       "      <td>0.900424</td>\n",
       "      <td>0.890843</td>\n",
       "      <td>0.789999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Raw Model  Bagging Model  AdaBoost Model  GBDT Model\n",
       "0         NN   0.862146       0.794817        0.857625    0.917142\n",
       "1        Net   0.613431       0.608018        0.676180    0.894815\n",
       "2      Ridge   0.864959       0.872336        0.849050    0.853443\n",
       "3       Tree   0.732819       0.882975        0.889707    0.875286\n",
       "4         BR   0.868200       0.880822        0.816866    0.883831\n",
       "5        KNR   0.703247       0.703247        0.699904    0.703247\n",
       "7        SVR   0.900424       0.900424        0.890843    0.789999"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_DF = pandas.DataFrame(Result_list, columns = [\"Model Name\",\"Raw Model\", \"Bagging Model\", \"AdaBoost Model\", \"GBDT Model\"])\n",
    "Result_DF.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num = 50\n",
    "xt = Test_X[:num]\n",
    "\n",
    "alpha = 0.6\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(NN.predict(xt), 'gd',alpha = alpha, label='NN')\n",
    "plt.plot(BR.predict(xt), 'ko',alpha = alpha, label='BR')\n",
    "plt.plot(Net.predict(xt), 'b^',alpha = alpha, label='Net')\n",
    "plt.plot(neigh.predict(xt), 'b+',alpha = alpha, label='KNR')\n",
    "plt.plot(Tree.predict(xt), 'cs',alpha = alpha, label='Tree')\n",
    "plt.plot(ridge.predict(xt), 'yp',alpha = alpha, label='Ridge')\n",
    "plt.plot(svr_poly.predict(xt), 'ys',alpha = alpha, label='SVR')\n",
    "\n",
    "plt.plot(ereg.predict(xt), 'r*',alpha = alpha, label='VotingRegressor')\n",
    "plt.plot(stregr.predict(xt), 'm*',alpha = alpha, label='StackingRegressor')\n",
    "\n",
    "\n",
    "plt.plot(Test_Y[:num], 'black', label='Y_Real')\n",
    "\n",
    "\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
    "                labelbottom=False)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('training samples')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Comparison of individual predictions with averaged')\n",
    "plt.savefig('result.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bagging - 降低variance 適合各種模型都做 ?\n",
    "\n",
    "\n",
    "Adaboost - 分類問題 效果較優?\n",
    "GBDT - 回歸問題 效果較優?\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
